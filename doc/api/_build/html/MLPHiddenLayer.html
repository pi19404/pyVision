
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
  
    <title>MLPHiddenLayer module &mdash; pyVision 0.0.1 documentation</title>
  <!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="_static/css/bootstrap.min.css" media="screen" />
  <link rel="stylesheet" href="_static/css/bootstrap-responsive.css"/>

    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="pyVision 0.0.1 documentation" href="index.html" />
    <link rel="next" title="Optimizer module" href="Optimizer.html" />
    <link rel="prev" title="LogisticRegression module" href="LogisticRegression.html" />
  
   
       <script type="text/javascript" src="_static/sidebar.js"></script>
   
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="_static/js/bootstrap.min.js" type="text/javascript"></script>
  <link rel="canonical" href="http://scikit-learn.org/stable/MLPHiddenLayer.html" />

  <script type="text/javascript">
    $("div.buttonNext, div.buttonPrevious").hover(
       function () {
           $(this).css('background-color', '#FF9C34');
       },
       function () {
           $(this).css('background-color', '#A7D6E2');
       }
    );
    var bodywrapper = $('.bodywrapper');
    var sidebarbutton = $('#sidebarbutton');
    sidebarbutton.css({'height': '900px'});
  </script>

  </head>
  <body>


<div class="header-wrapper">
    <div class="header"><div class="navbar">
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="https://github.com/pi19404/OpenVision">Source</a></li>            
            </ul>

            <div class="search_form">
                <div id="cse" style="width: 100%;"></div>
            </div>
        </div> <!-- end navbar --></div>
</div>


<!-- Github "fork me" ribbon -->
<a href="https://github.com/pi19404/OpenVision">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
    <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
        <div class="rel rellarge">
    

  <!-- rellinks[1:] is an ugly hack to avoid link to module
  index -->
        <div class="rellink">
        <a href="LogisticRegression.html"
        accesskey="P">Previous
        <br/>
        <span class="smallrellink">
        LogisticRegressi...
        </span>
            <span class="hiddenrellink">
            LogisticRegression module
            </span>
        </a>
        </div>
            <div class="spacer">
            &nbsp;
            </div>
        <div class="rellink">
        <a href="Optimizer.html"
        accesskey="N">Next
        <br/>
        <span class="smallrellink">
        Optimizer module
        </span>
            <span class="hiddenrellink">
            Optimizer module
            </span>
        </a>
        </div>
            <div class="spacer">
            &nbsp;
            </div>
        <div class="rellink">
        <a href="py-modindex.html"
        >Modules
        <br/>
        <span class="smallrellink">
        Python Module In...
        </span>
            <span class="hiddenrellink">
            Python Module Index
            </span>
        </a>
        </div>

    <!-- Ad a link to the 'up' page -->
    </div>
    
      <p class="doc-version">This documentation is for pyVision <strong>version 0.0.1</strong> &mdash; </p>
    <p class="citing">If you use the software, please consider citing pyVision</a>.</p>
    <ul>
<li><a class="reference internal" href="#">MLPHiddenLayer module</a></li>
</ul>

    </div>
</div>



      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="module-MLPHiddenLayer">
<span id="mlphiddenlayer-module"></span><h1>MLPHiddenLayer module<a class="headerlink" href="#module-MLPHiddenLayer" title="Permalink to this headline">¶</a></h1>
<p>Multi Layer Perceptron</p>
<dl class="class">
<dt id="MLPHiddenLayer.HiddenLayer">
<em class="property">class </em><tt class="descclassname">MLPHiddenLayer.</tt><tt class="descname">HiddenLayer</tt><big>(</big><em>n_in=None</em>, <em>n_out=None</em>, <em>activation=None</em>, <em>Reg=2</em>, <em>W=None</em>, <em>b=None</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#HiddenLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.HiddenLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>the class absracts the hidden layer in a Multi Layer perceptron feed forward neural network 
and is essentially a collection of neurons</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>n_in</strong> :  dimension of input vector</p>
<p><strong>n_out</strong> :  dimension of the output vector</p>
<p><strong>activation</strong> : activation function typicall sigmoid or tanh</p>
<p><strong>Reg</strong> : regularization option 1=L1 and 2=L2</p>
<p><strong>W,b</strong> : intial weight matrix and bias vector</p>
<p class="last"><strong>W is matix of dimension n_inxn_out and b is vector of size n_outx1</strong></p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>&gt;&gt; hidden_layer=HiddenLayer(n_in=n_in, n_out=n_hidden_units,activation=sigmoid_stable)</p>
<p>&gt;&gt; y=hidden_layer.compute(input);</p>
<p>in the below functions docstring</p>
<p>n_hidden denotes the number of output units of present hidden layer</p>
<p>n_out denotes the number of output units of next hidden layer</p>
<p>n_in denotes the size of input vector to present hidden layer</p>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="3%" />
<col width="97%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><cite>out</cite></td>
<td>(array-like ,shape=(n_out,)) The output of hidden layer</td>
</tr>
<tr class="row-even"><td><cite>params</cite></td>
<td>(array-like ,shape=(n_out,n_in+1)) contains the parameters in a flattened structure</td>
</tr>
<tr class="row-odd"><td><cite>W,b</cite></td>
<td>(array-like,shape=(n_out,n_int),shape=(n_out,1)) weight matrix and bias vector characterizing the hidden layer  <cite>activation</cite> : input activation the non linear activation function that is applied after performing affine transformation over input vector.</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<dl class="method">
<dt id="MLPHiddenLayer.HiddenLayer.activation_gradient">
<tt class="descname">activation_gradient</tt><big>(</big><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#HiddenLayer.activation_gradient"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.HiddenLayer.activation_gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>computes gradient of activation function for output of hidden layer over all input samples N</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>output</strong> : ndarray , shape=(n_out,)</p>
<blockquote class="last">
<div><p><span class="math">\(h_k(x)=f(a_k)=\begin{align} \frac{\partial \mathbf{h}_{k-1,j} }{\partial \mathbf{a}_{k-1,j}} \end{align}\)</span>
gradient of activation function</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.HiddenLayer.compute">
<tt class="descname">compute</tt><big>(</big><em>input</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#HiddenLayer.compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.HiddenLayer.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>function computes the output of the hidden layer for input matrix</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>input</strong> :   ndarray,shape=(N,n_in)</p>
<blockquote>
<div><p><span class="math">\(h_{i-1}(x)\)</span> is the <cite>input</cite></p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>output</strong> : ndarray ,shape=(N,n_out)</p>
<blockquote class="last">
<div><p><span class="math">\(f(b_k + w_k^T h_{i-1}(x))\)</span> ,affine transformation over input</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.HiddenLayer.compute_error">
<tt class="descname">compute_error</tt><big>(</big><em>x</em>, <em>w</em>, <em>y</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#HiddenLayer.compute_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.HiddenLayer.compute_error" title="Permalink to this definition">¶</a></dt>
<dd><p>function computes the gradient of the likelyhood function wrt to parameters  of the hidden layer for single input</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x</strong> : ndarray,shape=(n_hidden,)</p>
<blockquote>
<div><p><cite>x</cite> represents <span class="math">\(\begin{align} \frac{\partial \mathbf{h}_{k,j} }{\partial \mathbf{a}_{k,j}} \end{align}\)</span>,the gradient of activation function wrt to input</p>
</div></blockquote>
<p><strong>w</strong> : ndarray,shape=(n_hidden,)</p>
<blockquote>
<div><p><cite>w</cite> represents <span class="math">\(\begin{align} \frac{\partial L }{\partial \mathbf{h}_{k,i}}\end{align}\)</span> the gradient of the likelyhood fuction wrt output of hidden layer</p>
</div></blockquote>
<p><strong>y</strong> : ndarray,shape=(n_in,)</p>
<blockquote>
<div><p><cite>y</cite> represents <span class="math">\(\mathbf{h}_{k-2,j}\)</span> the input hidden layer</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>res</strong> : ndarray,shape=(n_in+1,n_hidden)</p>
<blockquote class="last">
<div><p><span class="math">\(\begin{align} \frac{\partial L }{\partial \mathbf{W}_{k-1,i,j}}  \text{ and } \frac{\partial L }{\partial \mathbf{W}_{k-1,i}} \end{align}\)</span></p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.HiddenLayer.cost_gradients">
<tt class="descname">cost_gradients</tt><big>(</big><em>weights</em>, <em>activation</em>, <em>error</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#HiddenLayer.cost_gradients"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.HiddenLayer.cost_gradients" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>function to compute the gradient of log likelyhood function wrt the parameters of the hidden layer</dt>
<dd>averaged over all the input samples.</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>weights</strong> : numpy,shape(n_out,n_hidden),</p>
<blockquote>
<div><blockquote>
<div><p>weight matrix of the next layer,W_{k,i,j}</p>
</div></blockquote>
<dl class="docutils">
<dt>activation: numpy,shape=(N,n_in)</dt>
<dd><p class="first last">input to the hidden layer mathbf{h}_{k-2,j}</p>
</dd>
<dt>error <span class="classifier-delimiter">:</span> <span class="classifier">numpy,shape=(n_out,) </span></dt>
<dd><p class="first last">, error of next  layer</p>
</dd>
</dl>
</div></blockquote>
<p><strong>rac{partial L }{partial mathbf{a}_{k,i}}</strong></p>
<blockquote class="last">
<div><p>Returns</p>
<dl class="docutils">
<dt>gW <span class="classifier-delimiter">:</span> <span class="classifier">ndarray,shape=(n_hidden,n_in+1)</span></dt>
<dd><p class="first last">coefficient parameter matrix of next hidden layer,
<span class="math">\(\begin{align} \frac{\partial L }{\partial \mathbf{W}_{k-1,i,j}}  \text{ and } \frac{\partial L }{\partial \mathbf{W}_{k-1,i}} \end{align}\)</span></p>
</dd>
</dl>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.HiddenLayer.linear_gradient">
<tt class="descname">linear_gradient</tt><big>(</big><em>weights</em>, <em>error</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#HiddenLayer.linear_gradient"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.HiddenLayer.linear_gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>The function compues gradient of likelihood function wrt output of hidden layer
<span class="math">\(\begin{align} \frac{\partial L }{\partial \mathbf{h}_{k-1,j}} \end{align}\)</span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>weights</strong> : ndarray,shape=(n_out,n_hidden)</p>
<blockquote>
<div><p>weights of next hidden layer, <span class="math">\(\begin{align} \mathbf{W}_{k,i,j}  \end{align}\)</span></p>
</div></blockquote>
<p><strong>error</strong> : ndarray,shape=(n_out,)</p>
<blockquote>
<div><p>backpropagated error from next layer <span class="math">\(\begin{align} \frac{\partial L }{\partial \mathbf{a}_{k,i}} \end{align}\)</span></p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>out</strong> : ndarray,shape=(n_hidden,)</p>
<blockquote class="last">
<div><p>compute the backpropagated error, <span class="math">\(\begin{align} \frac{\partial L }{\partial \mathbf{h}_{k-1,j}} \end{align}\)</span></p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.HiddenLayer.set_training_data">
<tt class="descname">set_training_data</tt><big>(</big><em>args</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#HiddenLayer.set_training_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.HiddenLayer.set_training_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to set the training data for current computation loop
useful in running algorithms for batch processing</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>args :tuple,shape=[(N,n_in),(N,n_out)]</strong></p>
<blockquote class="last">
<div><p>training data</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.HiddenLayer.update_parameters">
<tt class="descname">update_parameters</tt><big>(</big><em>params</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#HiddenLayer.update_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.HiddenLayer.update_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>function to updated the learn parameters to the model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>grads</strong> : ndarray,shape=(n_hidden,n_in+1)</p>
<blockquote class="last">
<div><p>coefficient parameter matrix</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="MLPHiddenLayer.MLP">
<em class="property">class </em><tt class="descclassname">MLPHiddenLayer.</tt><tt class="descname">MLP</tt><big>(</big><em>n_in</em>, <em>n_hidden_layers</em>, <em>n_hidden_units</em>, <em>n_out</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>Class with implements the Multi layer perceptron feed forward neural networks</p>
<p class="rubric">Methods</p>
<dl class="method">
<dt id="MLPHiddenLayer.MLP.callback">
<tt class="descname">callback</tt><big>(</big><em>w</em>, <em>num</em>, <em>x</em>, <em>y</em>, <em>flag</em>, <em>eta</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.callback"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.callback" title="Permalink to this definition">¶</a></dt>
<dd><p>The callback function from optimizer,can be used to display periodic updates</p>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.MLP.classify">
<tt class="descname">classify</tt><big>(</big><em>x</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.classify" title="Permalink to this definition">¶</a></dt>
<dd><p>the method performs classificaiton by assigning each input vector x to one of defined class lables</p>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.MLP.cost">
<tt class="descname">cost</tt><big>(</big><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.cost"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.cost" title="Permalink to this definition">¶</a></dt>
<dd><p>the function computer the likelyhood taking into account regularization over all hidden layers</p>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.MLP.lable">
<tt class="descname">lable</tt><big>(</big><em>y</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.lable"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.lable" title="Permalink to this definition">¶</a></dt>
<dd><p>mapping functions for output label and probability</p>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.MLP.learn">
<tt class="descname">learn</tt><big>(</big><em>update</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.learn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>the main function that performs learning,computing gradients and updating parameters </dt>
<dd>this is called by the optimizer module for each iteration</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>update - python function</strong></p>
<blockquote class="last">
<div><p>this represents the update function that performs the gradient descent iteration</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.MLP.load">
<tt class="descname">load</tt><big>(</big><em>file_name</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.load" title="Permalink to this definition">¶</a></dt>
<dd><p>the method loads the trained model parameters from output file</p>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.MLP.predict">
<tt class="descname">predict</tt><big>(</big><em>x</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>the function predicts the output of the MLP feed forward network given the input X</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x</strong> : numpy array,shape=(n_in,)</p>
<blockquote>
<div><p>input vector for classification</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>o</strong> : numpy array,shape=(n_out,)</p>
<blockquote class="last">
<div><p>vector that contains prediction probability that input vector belongs to output</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.MLP.probability">
<tt class="descname">probability</tt><big>(</big><em>y</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.probability"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.probability" title="Permalink to this definition">¶</a></dt>
<dd><p>mapping functions for output label and probability</p>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.MLP.propagate_backward">
<tt class="descname">propagate_backward</tt><big>(</big><em>error</em>, <em>weights</em>, <em>input</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.propagate_backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.propagate_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>the function that executes the backward propagation loop on hidden layers</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>error</strong> : numpy array,shape=()</p>
<p><strong>weight</strong> : numpy array,shape=()</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.MLP.propagate_forward">
<tt class="descname">propagate_forward</tt><big>(</big><em>input</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.propagate_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.propagate_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>the function that performs forward iteration to compute the output</p>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.MLP.save">
<tt class="descname">save</tt><big>(</big><em>file_name</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.save" title="Permalink to this definition">¶</a></dt>
<dd><p>the function saves the trainied model parameters to output file</p>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.MLP.set_training_data">
<tt class="descname">set_training_data</tt><big>(</big><em>args</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.set_training_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.set_training_data" title="Permalink to this definition">¶</a></dt>
<dd><p>function to set the training data for current computation loop</p>
</dd></dl>

<dl class="method">
<dt id="MLPHiddenLayer.MLP.train">
<tt class="descname">train</tt><big>(</big><em>train</em>, <em>test</em>, <em>validate</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#MLP.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.MLP.train" title="Permalink to this definition">¶</a></dt>
<dd><p>the main training function,that initialzes the optimizer
and starts the training process</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="MLPHiddenLayer.grad_sigmoid">
<tt class="descclassname">MLPHiddenLayer.</tt><tt class="descname">grad_sigmoid</tt><big>(</big><em>X</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#grad_sigmoid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.grad_sigmoid" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="data">
<dt id="MLPHiddenLayer.rng">
<tt class="descclassname">MLPHiddenLayer.</tt><tt class="descname">rng</tt><em class="property"> = &lt;mtrand.RandomState object at 0x540e330&gt;</em><a class="headerlink" href="#MLPHiddenLayer.rng" title="Permalink to this definition">¶</a></dt>
<dd><p>logistic function</p>
</dd></dl>

<dl class="function">
<dt id="MLPHiddenLayer.sigmoid">
<tt class="descclassname">MLPHiddenLayer.</tt><tt class="descname">sigmoid</tt><big>(</big><em>X</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#sigmoid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.sigmoid" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the sigmoid function</p>
</dd></dl>

<dl class="function">
<dt id="MLPHiddenLayer.sigmoid_stable">
<tt class="descclassname">MLPHiddenLayer.</tt><tt class="descname">sigmoid_stable</tt><big>(</big><em>x</em><big>)</big><a class="reference internal" href="_modules/MLPHiddenLayer.html#sigmoid_stable"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MLPHiddenLayer.sigmoid_stable" title="Permalink to this definition">¶</a></dt>
<dd><p>Numerically-stable sigmoid function.</p>
</dd></dl>

</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2014, pi19404.
      <a href="_sources/MLPHiddenLayer.txt" rel="nofollow">Show this page source</a>
    </div>
     <div class="rel rellarge">
    
    <div class="buttonPrevious">
      <a href="LogisticRegression.html">Previous
      </a>
    </div>
    <div class="buttonNext">
      <a href="Optimizer.html">Next
      </a>
    </div>
    <div class="buttonPrevious">
      <a href="py-modindex.html">Previous
      </a>
    </div>
    
     </div>

    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-22606712-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    

    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript"> google.load('search', '1',
        {language : 'en'}); google.setOnLoadCallback(function() {
            var customSearchControl = new
            google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
            customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
            var options = new google.search.DrawOptions();
            options.setAutoComplete(true);
            customSearchControl.draw('cse', options); }, true);
    </script>
  </body>
</html>